{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_example = input('Path or Example:')\n",
    "FILE_PATH = None\n",
    "SAMPLES = {\n",
    "    1: 'KOAX_20240521_1844',\n",
    "    2: 'KOAX_20240521_1849',\n",
    "    3: 'KOAX_20240523_2138',\n",
    "\n",
    "}\n",
    "if select_example.isdigit():\n",
    "    FILE_PATH = f\"{'./Samples/'}{SAMPLES[int(select_example)]}\" # I don't care if it is out of range, I just want to test the code\n",
    "else:\n",
    "    FILE_PATH = select_example\n",
    "import os\n",
    "fsize = os.stat(FILE_PATH).st_size\n",
    "f = open(FILE_PATH, 'rb')\n",
    "import bz2\n",
    "import namedstruct as ns\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "VHR = ns.nstruct(\n",
    "    (ns.char[6],'Tape'),            # Magic number: AR2V00\n",
    "    (ns.char[2],'Version'),         # Version number\n",
    "    (ns.char[1],'End of Tape'),     # End of Tape marker\n",
    "    (ns.char[3],'Sequence Number'), # Extension number\n",
    "    (ns.uint32,'Date_d'),           # Date of Volume, days since 1/1/1970\n",
    "    (ns.uint32,'Time_ms'),          # Time of Volume, milliseconds since midnight\n",
    "    (ns.char[4],'Station'),         # Station ID (ICAO)\n",
    "    name='VHR',padding=1,endian='>')\n",
    "LDM_CR = ns.nstruct(\n",
    "    (ns.int32,'ctrl_word'),      # Control word - lenth of the compressed data\n",
    "    (ns.raw,'data'),                       # This data is bz2 compressed when saved\n",
    "    name='LDM_CR',padding=1,endian='>') # TODO: Need to tell it to compress when packing, save the size to the control word\n",
    "\n",
    "\n",
    "L2A = ns.nstruct(\n",
    "    (VHR,'VHR'),                       # Volume Header Record\n",
    "    (LDM_CR[0],'records'),             # LDM_CR records \n",
    "    name='L2A',padding=1,endian='>')\n",
    "\n",
    "# test = VHR.parse(f.read(24))\n",
    "fi, __ = L2A.parse(f.read())\n",
    "# go back to the first LDM_CR\n",
    "f.seek(24)\n",
    "while(f.tell() < fsize): # read each LDM_CR into a record and add it to the archive - we do this since the datatype is raw here.\n",
    "    l = f.tell()\n",
    "    s = int.from_bytes(f.read(4))\n",
    "    if(s==b'\\xff\\xff'):\n",
    "        break\n",
    "    f.seek(l)\n",
    "    d = f.read(s+4)\n",
    "    if (d == b''):\n",
    "        log.debug('bad data')\n",
    "    ldm = LDM_CR.create(d)\n",
    "    fi.records.append(ldm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 94\n",
      "104 136- header: b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00D\\x08\\x02\\x08iM\\x99\\x04\\x0c\\x86\\x11\\x00\\x01\\x00\\x01\\x00\\x10\\x00\\x02\\x00\\x04\\x00\\x02\\x04\\xc2'\n",
      "tail: b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n'\n",
      "148\n"
     ]
    },
    {
     "ename": "BadLenError",
     "evalue": "Cannot parse struct: data is corrupted.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadLenError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[293], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m#TODO: parse the message into the correct message type instead of raw data\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m a_record_that_exists \u001b[38;5;241m=\u001b[39m \u001b[43mmsg_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     85\u001b[0m ldm\u001b[38;5;241m.\u001b[39mmsg\u001b[38;5;241m.\u001b[39mappend(a_record_that_exists)\n\u001b[0;32m     86\u001b[0m position\u001b[38;5;241m=\u001b[39meom\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\namedstruct\\namedstruct.py:1506\u001b[0m, in \u001b[0;36mtypedef.create\u001b[1;34m(self, buffer)\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m, buffer):\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;124;03m    Create a object from all the bytes. If there are additional bytes, they may be fed greedily to\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;124;03m    a variable length type, or may be used as \"extra\" data.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;124;03m    :raises: BadFormatError or BadLenError if the bytes cannot completely form this type.\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\namedstruct\\namedstruct.py:772\u001b[0m, in \u001b[0;36mParser.create\u001b[1;34m(self, data, inlineparent)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase\u001b[38;5;241m.\u001b[39mcreate(data, inlineparent)\n\u001b[1;32m--> 772\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minlineparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubclass(c)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\namedstruct\\namedstruct.py:756\u001b[0m, in \u001b[0;36mParser._create\u001b[1;34m(self, data, inlineparent)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, inlineparent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    755\u001b[0m     c \u001b[38;5;241m=\u001b[39m _create_struct(\u001b[38;5;28mself\u001b[39m, inlineparent)\n\u001b[1;32m--> 756\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\namedstruct\\namedstruct.py:99\u001b[0m, in \u001b[0;36mNamedStruct._unpack\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     97\u001b[0m current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m current \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     last \u001b[38;5;241m=\u001b[39m current\n\u001b[0;32m    101\u001b[0m     current \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(current, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_sub\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\namedstruct\\namedstruct.py:1076\u001b[0m, in \u001b[0;36mSequencedParser.unpack\u001b[1;34m(self, data, namedstruct)\u001b[0m\n\u001b[0;32m   1074\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parseinner(data, namedstruct, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1076\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadLenError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot parse struct: data is corrupted.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     extra \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(namedstruct, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_extra\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mBadLenError\u001b[0m: Cannot parse struct: data is corrupted."
     ]
    }
   ],
   "source": [
    "\n",
    "if True:\n",
    "    f.close() # close the file\n",
    "    log.setLevel(0)\n",
    "msg_header_channel_enum = ns.enum('msg_header_channel_enum', None, ns.uint8, bitwise=False,\n",
    "                    # Note: if both redundent channels are 0s, single channel mode. \n",
    "                           RC_1 = 0,    # redundant channel 1\n",
    "                           RC_2 = 1,    # redundant channel 2\n",
    "                           unused = 2,  # unused. \n",
    "                           ORDA = 3     # ORDA channel (vs legacy)\n",
    "                           )\n",
    "# Message header structure \n",
    "msg_header = ns.nstruct(\n",
    "        (ns.uint32[3],'prepad'),                # padding\n",
    "        (ns.uint16,'message_size'),             # size of message in halfwords\n",
    "        (msg_header_channel_enum,'channel'),    # actually bit field\n",
    "        (ns.uint8,'message_type'),              # type of message\n",
    "        (ns.uint16,'sequence'),                 # sequence number of message\n",
    "        (ns.uint16,'date'),                     # days since 1/1/1970\n",
    "        (ns.uint32,'milliseconds'),             # milliseconds since midnight\n",
    "        # Remember, is these 2 are not 1, then the message is extended and needs to be combined with the next message\n",
    "        (ns.uint16,'segments'),                 # number of segments in message  \n",
    "        (ns.uint16,'segment'),                  # segment number of this message\n",
    "        name='msg_header', padding=1, prepack=ns.packvalue(2432,'message_size'), endian='>') # TODO: Use size of message to determine size of message \n",
    "\n",
    "# Base message structure\n",
    "msg_base = ns.nstruct(\n",
    "    (msg_header,'header'),\n",
    "    (ns.raw,'data'),\n",
    "    name='msg_base',padding=1,endian='>')\n",
    "\n",
    "# UNCOMPRESSED RECORD data\n",
    "LDM_UR = ns.nstruct(\n",
    "    (msg_base[0],'msg'),                # Messages - not sure that this will work since it will hold extended data\n",
    "    name='LDM_UR',padding=1,endian='>') # TODO: Need to tell it to compress when packing, save the size to the control word\n",
    "\n",
    "log.setLevel(1000)\n",
    "\n",
    "print(f\"Number of records: {len(fi.records)}\")\n",
    "\n",
    "record = 0\n",
    "ldm = LDM_UR.create('')\n",
    "for cr in fi.records:\n",
    "    if(cr.ctrl_word < 0):\n",
    "        break\n",
    "    data = bz2.decompress(cr.data[:cr.ctrl_word])\n",
    "    if data == b'':\n",
    "        log.error(f\"Error decompressing data. CW: {cr.ctrl_word}\")\n",
    "        break\n",
    "\n",
    "\n",
    "    position = 0 # position in the data\n",
    "    i = 0 # message counter\n",
    "    while(position<len(data)):\n",
    "        msg_size = int.from_bytes(data[position+12:position+14]) # get size in halfwords\n",
    "        if(msg_size > 65535):\n",
    "            log.error(f\"Error: Message size too large: {msg_size}\")\n",
    "            break\n",
    "        elif(msg_size<9):\n",
    "            log.warning(f\"Error?: Message size too small: {msg_size}\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if(record == 0):\n",
    "            eom = 2432*(i+1)\n",
    "            break\n",
    "        else:\n",
    "            eom = position+msg_size*2+12\n",
    "            # print(data[position:position+15])\n",
    "            # print(f\"expecting end: {dat[eom-6:eom+30]}\")\n",
    "        \n",
    "        log.error(f\"Message size: {msg_size}\")\n",
    "        dat = data[position:eom]\n",
    "        if dat[0:12] != b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00':\n",
    "            log.error(f\"Error: Prepad {i} is not 0: {dat[0:12]}\")\n",
    "        elif (dat[12:14] == b'\\x00\\x00' or dat[12:14] == b''):\n",
    "            log.info(f\"in {i}: too many 0s: {dat[0:28]}\")\n",
    "        else:\n",
    "            if record == 46 and i > 103:\n",
    "                print(f\"{i} {msg_size*2}- header: {dat[0:38]}\")\n",
    "                print(f\"tail: {dat[-30:]}\")\n",
    "                print(len(dat))\n",
    "            pass\n",
    "        #TODO: parse the message into the correct message type instead of raw data\n",
    "        a_record_that_exists = msg_base.create(dat) \n",
    "        ldm.msg.append(a_record_that_exists)\n",
    "        position=eom\n",
    "        i+=1\n",
    "    # if(record>47):\n",
    "    #     break\n",
    "    record+=1\n",
    "\n",
    "log.setLevel(1000)\n",
    "prods = {}\n",
    "totals = 0\n",
    "for i, a in enumerate(ldm.msg):\n",
    "    # Running this will create a lot of warnings. It is not being parsed correctly.\n",
    "    if a.header.message_type > 33:\n",
    "        log.warning(f\"Message {i} type {a.header.message_type} is not valid!\")\n",
    "    if a.header.message_type == 0:\n",
    "        log.info(f\"Message {i} has type 0. Likley a type 13 legacy area.\")\n",
    "    if a.header.milliseconds >= 86400000:\n",
    "        log.warning(f\"Message {i} time is invalid: {a.header.milliseconds}\")\n",
    "    if a.header.segments != 1 or a.header.segment != 1:\n",
    "        log.warning(f\"Message {i} has segments: {a.header.segment} of {a.header.segments}\")\n",
    "    if a.header.date > 65535:\n",
    "        log.warning(f\"Message {i} date is invalid: {a.header.date}\")\n",
    "    if a.header.sequence > 65535:\n",
    "        log.warning(f\"Message {i} sequence is invalid: {a.header.sequence}\")\n",
    "    if a.header.channel > 10:\n",
    "        log.warning(f\"Message {i} redundent channel is invalid: {a.header.channel}\")\n",
    "    if a.header.message_size > 65535:\n",
    "        log.warning(f\"Message {i} size is invalid: {a.header.message_size}\")\n",
    "    if a.header.prepad[0] != 0 or a.header.prepad[1] != 0 or a.header.prepad[2] != 0:\n",
    "        log.warning(f\"Message {i} Prepad is not 0: {a.header.prepad}\")\n",
    "    log.warning(f\"...Message {i}: {a.header.message_type} has sequence number {a.header.sequence} and is {a.header.message_size} halfwords\")\n",
    "    prods[a.header.message_type] = prods.get(a.header.message_type,0)+1\n",
    "    totals+=1\n",
    "print(prods)\n",
    "print(totals)\n",
    "# 3.2.4.17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Blocks:\n",
    "## Metadata\n",
    "1. Message 15 - up to 77 Segments\n",
    "2. Message 13 - up to 49 Segments - WIll be 0s after build 19\n",
    "3. Message 18 - 5 Segments\n",
    "4. Message 3 - 1 Segment\n",
    "5. Message 5 - 1 Segment\n",
    "6. Message 2 - 1 Segment\n",
    "TOTAL: 134 Segments/Messagges\n",
    "## Data \n",
    "- Type 31 * 120 radials\n",
    "- Type 2 * (0+)\n",
    "## Model Data \n",
    "- Type 29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
