{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_example = input('Path or Example:')\n",
    "FILE_PATH = None\n",
    "SAMPLES = {\n",
    "    1: 'KOAX_20240521_1844',\n",
    "    2: 'KOAX_20240521_1849',\n",
    "    3: 'KOAX_20240523_2138',\n",
    "\n",
    "}\n",
    "if select_example.isdigit():\n",
    "    FILE_PATH = f\"{'./Samples/'}{SAMPLES[int(select_example)]}\" # I don't care if it is out of range, I just want to test the code\n",
    "else:\n",
    "    FILE_PATH = select_example\n",
    "import os\n",
    "fsize = os.stat(FILE_PATH).st_size\n",
    "f = open(FILE_PATH, 'rb')\n",
    "import bz2\n",
    "import namedstruct as ns\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "VHR = ns.nstruct(\n",
    "    (ns.char[6],'Tape'),            # Magic number: AR2V00\n",
    "    (ns.char[2],'Version'),         # Version number\n",
    "    (ns.char[1],'End of Tape'),     # End of Tape marker\n",
    "    (ns.char[3],'Sequence Number'), # Extension number\n",
    "    (ns.uint32,'Date_d'),           # Date of Volume, days since 1/1/1970\n",
    "    (ns.uint32,'Time_ms'),          # Time of Volume, milliseconds since midnight\n",
    "    (ns.char[4],'Station'),         # Station ID (ICAO)\n",
    "    name='VHR',padding=1,endian='>')\n",
    "LDM_CR = ns.nstruct(\n",
    "    (ns.int32,'ctrl_word'),      # Control word - lenth of the compressed data\n",
    "    (ns.raw,'data'),                       # This data is bz2 compressed when saved\n",
    "    name='LDM_CR',padding=1,endian='>') # TODO: Need to tell it to compress when packing, save the size to the control word\n",
    "\n",
    "\n",
    "L2A = ns.nstruct(\n",
    "    (VHR,'VHR'),                       # Volume Header Record\n",
    "    (LDM_CR[0],'records'),             # LDM_CR records \n",
    "    name='L2A',padding=1,endian='>')\n",
    "\n",
    "# test = VHR.parse(f.read(24))\n",
    "fi, __ = L2A.parse(f.read())\n",
    "# go back to the first LDM_CR\n",
    "f.seek(24)\n",
    "while(f.tell() < fsize): # read each LDM_CR into a record and add it to the archive - we do this since the datatype is raw here.\n",
    "    l = f.tell()\n",
    "    s = int.from_bytes(f.read(4))\n",
    "    if(s==b'\\xff\\xff'):\n",
    "        break\n",
    "    f.seek(l)\n",
    "    d = f.read(s+4)\n",
    "    if (d == b''):\n",
    "        log.debug('bad data')\n",
    "    ldm = LDM_CR.create(d)\n",
    "    fi.records.append(ldm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 94\n",
      "{15: 5, 31: 10898, 2: 2}\n",
      "10905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if True:\n",
    "    f.close() # close the file\n",
    "    log.setLevel(0)\n",
    "msg_header_channel_enum = ns.enum('msg_header_channel_enum', None, ns.uint8, bitwise=False,\n",
    "                    # Note: if both redundent channels are 0s, single channel mode. \n",
    "                           RC_1 = 0,    # redundant channel 1\n",
    "                           RC_2 = 1,    # redundant channel 2\n",
    "                           unused = 2,  # unused. \n",
    "                           ORDA = 3     # ORDA channel (vs legacy)\n",
    "                           )\n",
    "# Message header structure \n",
    "msg_header = ns.nstruct(\n",
    "        (ns.uint32[3],'prepad'),                # padding\n",
    "        (ns.uint16,'message_size'),             # size of message in halfwords\n",
    "        (msg_header_channel_enum,'channel'),    # actually bit field\n",
    "        (ns.uint8,'message_type'),              # type of message\n",
    "        (ns.uint16,'sequence'),                 # sequence number of message\n",
    "        (ns.uint16,'date'),                     # days since 1/1/1970\n",
    "        (ns.uint32,'milliseconds'),             # milliseconds since midnight\n",
    "        # Remember, is these 2 are not 1, then the message is extended and needs to be combined with the next message\n",
    "        (ns.uint16,'segments'),                 # number of segments in message  \n",
    "        (ns.uint16,'segment'),                  # segment number of this message\n",
    "        name='msg_header', padding=1, prepack=ns.packvalue(2432,'message_size'), endian='>') # TODO: Use size of message to determine size of message \n",
    "\n",
    "# Base message structure\n",
    "msg_base = ns.nstruct(\n",
    "    (msg_header,'header'),\n",
    "    (ns.raw,'data'),\n",
    "    name='msg_base',padding=1,endian='>')\n",
    "\n",
    "# UNCOMPRESSED RECORD data\n",
    "LDM_UR = ns.nstruct(\n",
    "    (msg_base[0],'msg'),                # Messages - not sure that this will work since it will hold extended data\n",
    "    name='LDM_UR',padding=1,endian='>') # TODO: Need to tell it to compress when packing, save the size to the control word\n",
    "\n",
    "log.setLevel(logging.FATAL-1)\n",
    "record_count = len(fi.records)\n",
    "print(f\"Number of records: {record_count}\")\n",
    "\n",
    "record = 0\n",
    "ldm = LDM_UR.create('')\n",
    "for cr in fi.records:\n",
    "    if(cr.ctrl_word < 0):\n",
    "        break\n",
    "    data = bz2.decompress(cr.data[:cr.ctrl_word])\n",
    "    if data == b'':\n",
    "        log.error(f\"Error decompressing data. CW: {cr.ctrl_word}\")\n",
    "        break\n",
    "\n",
    "\n",
    "    position = 0 # position in the data\n",
    "    i = 0 # message counter\n",
    "    while(position<len(data)):\n",
    "        msg_size = int.from_bytes(data[position+12:position+14]) # get size in halfwords\n",
    "        if(msg_size > 65535):\n",
    "            log.error(f\"Error: Message size too large: {msg_size}\")\n",
    "            raise Exception(f\"Stop {msg_size}\")\n",
    "            break\n",
    "        elif(msg_size<9):\n",
    "            if (msg_size != 0):\n",
    "                log.warning(f\"Error?: Message size too small: {msg_size}\")\n",
    "                raise Exception(f\"Stop {record}.{i}\")\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if(record == 0):\n",
    "            eom = 2432*(i+1)-12 # not really needed but..\n",
    "        else:\n",
    "            eom = position+msg_size*2\n",
    "        \n",
    "        dat = data[position:eom]\n",
    "        if dat[0:12] != b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00':\n",
    "            log.error(f\"Error: Prepad {i} is not 0: {dat[0:12]}\")\n",
    "        elif (dat[12:14] == b'\\x00\\x00' or dat[12:14] == b''):\n",
    "            pass\n",
    "            # log.info(f\"in {i}: too many 0s: {dat[0:28]}\")\n",
    "        else:\n",
    "            pass\n",
    "        #TODO: parse the message into the correct message type instead of raw data\n",
    "        a_record_that_exists = msg_base.create(dat) \n",
    "        ldm.msg.append(a_record_that_exists)\n",
    "        position=eom+12\n",
    "        i+=1\n",
    "\n",
    "    record+=1\n",
    "    # log.fatal(f\"going to next record {record}\")\n",
    "\n",
    "log.setLevel(1000)\n",
    "prods = {}\n",
    "totals = 0\n",
    "for i, a in enumerate(ldm.msg):\n",
    "    # Running this will create a lot of warnings. It is not being parsed correctly.\n",
    "    if a.header.message_type > 33:\n",
    "        log.warning(f\"Message {i} type {a.header.message_type} is not valid!\")\n",
    "    if a.header.message_type == 0:\n",
    "        log.info(f\"Message {i} has type 0. Likley a type 13 legacy area.\")\n",
    "    if a.header.milliseconds >= 86400000:\n",
    "        log.warning(f\"Message {i} time is invalid: {a.header.milliseconds}\")\n",
    "    if a.header.segments != 1 or a.header.segment != 1:\n",
    "        log.warning(f\"Message {i} has segments: {a.header.segment} of {a.header.segments}\")\n",
    "    if a.header.date > 65535:\n",
    "        log.warning(f\"Message {i} date is invalid: {a.header.date}\")\n",
    "    if a.header.sequence > 65535:\n",
    "        log.warning(f\"Message {i} sequence is invalid: {a.header.sequence}\")\n",
    "    if a.header.channel > 10:\n",
    "        log.warning(f\"Message {i} redundent channel is invalid: {a.header.channel}\")\n",
    "    if a.header.message_size > 65535:\n",
    "        log.warning(f\"Message {i} size is invalid: {a.header.message_size}\")\n",
    "    if a.header.prepad[0] != 0 or a.header.prepad[1] != 0 or a.header.prepad[2] != 0:\n",
    "        log.warning(f\"Message {i} Prepad is not 0: {a.header.prepad}\")\n",
    "    log.warning(f\"...Message {i}: {a.header.message_type} has sequence number {a.header.sequence} and is {a.header.message_size} halfwords\")\n",
    "    prods[a.header.message_type] = prods.get(a.header.message_type,0)+1\n",
    "    totals+=1\n",
    "print(prods)\n",
    "print(totals)\n",
    "# 3.2.4.17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Blocks:\n",
    "## Metadata\n",
    "1. Message 15 - up to 77 Segments\n",
    "2. Message 13 - up to 49 Segments - WIll be 0s after build 19\n",
    "3. Message 18 - 5 Segments\n",
    "4. Message 3 - 1 Segment\n",
    "5. Message 5 - 1 Segment\n",
    "6. Message 2 - 1 Segment\n",
    "TOTAL: 134 Segments/Messagges\n",
    "## Data \n",
    "- Type 31 * 120 radials\n",
    "- Type 2 * (0+)\n",
    "## Model Data \n",
    "- Type 29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
